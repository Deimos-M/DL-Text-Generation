{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght:  703829\n"
     ]
    }
   ],
   "source": [
    "#loading the data ; source:https://www.gutenberg.org/ebooks/1342\n",
    "text = open(r'pride.txt', encoding=\"utf8\")\n",
    "text = text.read().lower()\n",
    "print('lenght: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Just removed the starting useless part of the file\n",
    "text=text[625:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pride and prejudice\\n\\nby jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth universally acknowledged, that a single man in possession\\nof a good fortune, must be in want of a wife.\\n\\nhowever little known the feelings or views of such a man may be on his\\nfirst entering a neighbourhood, this truth is so well fixed in the minds\\nof the surrounding families, that he is considered the rightful property\\nof some one or other of their daughters.\\n\\n“my dear mr. bennet,” said his lady to him one day, “have you heard that\\nnetherfield park is let at last?”\\n\\nmr. bennet replied that he had not.\\n\\n“but it is,” returned she; “for mrs. long has just been here, and she\\ntold me all about it.”\\n\\nmr. bennet made no answer.\\n\\n“do you not want to know who has taken it?” cried his wife impatiently.\\n\\n“_you_ want to tell me, and i have no objection to hearing it.”\\n\\nthis was invitation enough.\\n\\n“why, my dear, you must know, mrs. long says that netherfield is taken\\nby a young man of large fortune from the north of england; that he'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character level text generation using language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences: 234382\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60 # extracting sequence of 60 characters\n",
    "step = 3 # sampling a new sequence every 3 characters\n",
    "sentences = [] # holds the extracted seq\n",
    "next_chars = [] # holds the targets(follow up char)\n",
    "\n",
    "for i in range(0, len(text)- maxlen,step):\n",
    "    sentences.append(text[i:i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "print('number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pride and prejudice\\n\\nby jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a t',\n",
       " 'de and prejudice\\n\\nby jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a trut',\n",
       " 'and prejudice\\n\\nby jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth u',\n",
       " ' prejudice\\n\\nby jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth univ',\n",
       " 'ejudice\\n\\nby jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth univers',\n",
       " 'dice\\n\\nby jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth universall',\n",
       " 'e\\n\\nby jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth universally a',\n",
       " 'by jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth universally ackn',\n",
       " 'jane austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth universally acknowl',\n",
       " 'e austen\\n\\n\\n\\nchapter 1\\n\\n\\nit is a truth universally acknowledg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is how it looks\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 'h', 'n', 'e', 'a', 'y', 'c', 'o', 'e', 'e']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique chars : 56\n"
     ]
    }
   ],
   "source": [
    "chars= sorted(list(set(text))) #holds the unique chars from the corpus\n",
    "print('Unique chars :',len(chars))\n",
    "char_indices= dict((char,chars.index(char)) for char in chars) #Dictionary that maps unique characters to their index in the list “chars”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorization\n",
    "#one-hot encoding the chars into the binary arrays\n",
    "x=np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool)\n",
    "y=np.zeros((len(sentences),len(chars)), dtype=np.bool)\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for t,char in enumerate(sentence):\n",
    "        x[i,t,char_indices[char]]=1\n",
    "    y[i,char_indices[next_chars[i]]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#building the network\n",
    "model = Sequential()\n",
    "model.add(layers.LSTM(128,input_shape=(maxlen,len(chars))))\n",
    "model.add(layers.Dense(len(chars),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to sample the next char given the model's predictions\n",
    "def sample(preds,temp=1.0):\n",
    "    preds =np.asarray(preds).astype('float64')\n",
    "    preds =np.log(preds)/temp\n",
    "    exp_preds =np.exp(preds)\n",
    "    preds = exp_preds/np.sum(exp_preds)\n",
    "    probas =np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 263s 1ms/step - loss: 1.8468\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 259s 1ms/step - loss: 1.4852\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 259s 1ms/step - loss: 1.4014\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 257s 1ms/step - loss: 1.3610\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 263s 1ms/step - loss: 1.3327\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 262s 1ms/step - loss: 1.3119\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 258s 1ms/step - loss: 1.2958\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 257s 1ms/step - loss: 1.2847\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 259s 1ms/step - loss: 1.2743\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 257s 1ms/step - loss: 1.2629\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 258s 1ms/step - loss: 1.2569\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 260s 1ms/step - loss: 1.2492\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 281s 1ms/step - loss: 1.2452\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 285s 1ms/step - loss: 1.2393\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 274s 1ms/step - loss: 1.2352\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 272s 1ms/step - loss: 1.2311\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 290s 1ms/step - loss: 1.2255\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 282s 1ms/step - loss: 1.2221\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 281s 1ms/step - loss: 1.2186\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 280s 1ms/step - loss: 1.2159\n",
      "epoch:  20\n",
      "\n",
      "---Generating with seed: \"posing. they have\n",
      "known her much longer than they have known\"\n",
      "\n",
      "-------temperature:  0.2\n",
      "posing. they have\n",
      "known her much longer than they have known the consenture of her the continual to her in the present the continual to the concerned to her attention of his sisters, and the like the present the having have at least, and the continuality of he\n",
      "-------temperature:  0.5\n",
      "posing. they have\n",
      "known her much longer than they have knownr father was have much attention for her anxiety of the interesting in seeing alone, indeed, and that the winded the party consent\n",
      "of manter. mrs. bene the feelings in the letter, and i will the contr\n",
      "-------temperature:  1.0\n",
      "posing. they have\n",
      "known her much longer than they have knownaral.\n",
      "\n",
      "her husband's\n",
      "restare herself of respected, and too crest be song in tikent arrive beg, “it was my sepress incliement, assurance elizabeth was gracious.”\n",
      "\n",
      "the\n",
      "subject, who did scyours,\n",
      "gaven, cEpoch 1/1\n",
      "234382/234382 [==============================] - 287s 1ms/step - loss: 1.2150\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 302s 1ms/step - loss: 1.2160\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 277s 1ms/step - loss: 1.2126\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 276s 1ms/step - loss: 1.2098\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 276s 1ms/step - loss: 1.2104\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 276s 1ms/step - loss: 1.2151\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 276s 1ms/step - loss: 1.2183\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 295s 1ms/step - loss: 1.2075\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 285s 1ms/step - loss: 1.2008\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 278s 1ms/step - loss: 1.1989\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 291s 1ms/step - loss: 1.2064\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 282s 1ms/step - loss: 1.2295\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 292s 1ms/step - loss: 1.2271\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 284s 1ms/step - loss: 1.2086\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 271s 1ms/step - loss: 1.2217\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 273s 1ms/step - loss: 1.2101\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 269s 1ms/step - loss: 1.2045\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 271s 1ms/step - loss: 1.2627\n",
      "Epoch 1/1\n",
      "234382/234382 [==============================] - 284s 1ms/step - loss: 1.2024\n",
      "epoch:  39\n",
      "\n",
      "---Generating with seed: \"e saw him thus seeking the acquaintance and courting the goo\"\n",
      "\n",
      "-------temperature:  0.2\n",
      "e saw him thus seeking the acquaintance and courting the good offered to the supposing the ladies of the suspect the others. i am sure i am sure i am sure i can be distress the project gutenberg-tm\n",
      "which her as soon as she was not as they were merely seen the \n",
      "-------temperature:  0.5\n",
      "e saw him thus seeking the acquaintance and courting the googreatest the rest of the gentlemen to walk of express of the amother only, and all the eldement at her with him. he was come to her remarkably day of his beht former of such the best time to london,” \n",
      "-------temperature:  1.0\n",
      "e saw him thus seeking the acquaintance and courting the goosaid "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss binglind timest, “and he is conn”““efeecal,\n",
      "had\n",
      "srighted at ne fully of the company acquaintance, satiness be suspiciess which had, unconmentment of she hastear\n",
      "parties not capimance which i"
     ]
    }
   ],
   "source": [
    "#text generation \n",
    "for epoch in range(1,40): #training the model for 60 epochs\n",
    "    model.fit(x,y,batch_size=128,epochs=1) #fit the model\n",
    "    if(epoch == 20 or epoch == 39):\n",
    "        print('epoch: ' ,epoch)\n",
    "        #select a seed at random\n",
    "        start_index = random.randint(0,len(text)-maxlen-1)\n",
    "        generated_text = text[start_index: start_index+ maxlen]\n",
    "        print('\\n---Generating with seed: \"'+ generated_text + '\"')\n",
    "        seed_text=generated_text\n",
    "        #using different temperatures\n",
    "        for temp in [0.2,0.5,1.0]:\n",
    "            print('\\n-------temperature: ',temp)\n",
    "            sys.stdout.write(seed_text)\n",
    "            for i in range(200): #generating 200 chars\n",
    "                #one hot encode the chars generated so far\n",
    "                sampled = np.zeros((1,maxlen,len(chars)))\n",
    "                for t,char in enumerate(generated_text):\n",
    "                    sampled[0,t,char_indices[char]] =1 \n",
    "                \n",
    "                #samples the next char\n",
    "                preds= model.predict(sampled, verbose=0)[0]\n",
    "                next_index = sample(preds,temp)\n",
    "                next_char = chars[next_index]\n",
    "                \n",
    "                generated_text += next_char\n",
    "                generated_text = generated_text[1:]\n",
    "                sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word level text generation using language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens : 121488\n",
      "Unique tokens : 6513\n"
     ]
    }
   ],
   "source": [
    "#lets do some preprocessing\n",
    "#replace '-' with ' '\n",
    "doc=text.replace('-',' ')\n",
    "#split into tokens by white space\n",
    "tokens=doc.split() \n",
    "#remove punctuation from each token\n",
    "table =str.maketrans('','',string.punctuation)\n",
    "tokens =[w.translate(table) for w in tokens]\n",
    "#remove remaining tokens that are not alphabetic\n",
    "tokens =[word for word in tokens if word.isalpha()]\n",
    "print('Total tokens :',len(tokens))\n",
    "print('Unique tokens :',len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences: 40486\n"
     ]
    }
   ],
   "source": [
    "maxlen = 30 # extracting sequence of 30 words\n",
    "step = 3 # sampling a new sequence every 3 words\n",
    "sentences = [] # holds the extracted seq\n",
    "next_words = [] # holds the targets(follow up words)\n",
    "\n",
    "for i in range(0, len(tokens)- maxlen,step):\n",
    "    sentences.append(' '.join(tokens[i:i+maxlen]))\n",
    "    next_words.append(tokens[i+maxlen])\n",
    "print('number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pride and prejudice by jane austen chapter it is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife',\n",
       " 'by jane austen chapter it is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife however little known',\n",
       " 'chapter it is a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife however little known the feelings or',\n",
       " 'a truth universally acknowledged that a single man in possession of a good fortune must be in want of a wife however little known the feelings or views of such',\n",
       " 'acknowledged that a single man in possession of a good fortune must be in want of a wife however little known the feelings or views of such a man may',\n",
       " 'single man in possession of a good fortune must be in want of a wife however little known the feelings or views of such a man may be on his',\n",
       " 'possession of a good fortune must be in want of a wife however little known the feelings or views of such a man may be on his first entering a',\n",
       " 'good fortune must be in want of a wife however little known the feelings or views of such a man may be on his first entering a neighbourhood this truth',\n",
       " 'be in want of a wife however little known the feelings or views of such a man may be on his first entering a neighbourhood this truth is so well',\n",
       " 'of a wife however little known the feelings or views of such a man may be on his first entering a neighbourhood this truth is so well fixed in the']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['however',\n",
       " 'the',\n",
       " 'views',\n",
       " 'a',\n",
       " 'be',\n",
       " 'first',\n",
       " 'neighbourhood',\n",
       " 'is',\n",
       " 'fixed',\n",
       " 'minds']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique chars : 6513\n"
     ]
    }
   ],
   "source": [
    "words= sorted(list(set(tokens))) #holds the unique words from the corpus\n",
    "print('Unique chars :',len(words))\n",
    "word_indices= dict((word,words.index(word)) for word in words) #Dictionary that maps unique word to their index in the list “word”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorization\n",
    "#one-hot encoding the tokens into the binary arrays\n",
    "x=np.zeros((len(sentences),maxlen,len(words)),dtype=np.bool)\n",
    "y=np.zeros((len(sentences),len(words)), dtype=np.bool)\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for t,word in enumerate(sentence.split()):\n",
    "        x[i,t,word_indices[word]]=1\n",
    "    y[i,word_indices[next_words[i]]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 128)               3400704   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6513)              840177    \n",
      "=================================================================\n",
      "Total params: 4,257,393\n",
      "Trainable params: 4,257,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building the network\n",
    "model = Sequential()\n",
    "model.add(layers.LSTM(128,input_shape=(maxlen,len(words))))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(len(words),activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to sample the next word given the model's predictions\n",
    "def sample(preds,temp=1.0):\n",
    "    preds =np.asarray(preds).astype('float64')\n",
    "    preds =np.log(preds)/temp\n",
    "    exp_preds =np.exp(preds)\n",
    "    preds = exp_preds/np.sum(exp_preds)\n",
    "    probas =np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 208s 5ms/step - loss: 6.4778 - acc: 0.0354\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 178s 4ms/step - loss: 5.9264 - acc: 0.0717\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 203s 5ms/step - loss: 5.5389 - acc: 0.1021\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 211s 5ms/step - loss: 5.2385 - acc: 0.1295\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 241s 6ms/step - loss: 4.9829 - acc: 0.1492\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 266s 7ms/step - loss: 4.7457 - acc: 0.1686\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 230s 6ms/step - loss: 4.5305 - acc: 0.1900\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 239s 6ms/step - loss: 4.3198 - acc: 0.2115\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 219s 5ms/step - loss: 4.1216 - acc: 0.2369\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 223s 6ms/step - loss: 3.9256 - acc: 0.2625\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 190s 5ms/step - loss: 3.7393 - acc: 0.2825\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 247s 6ms/step - loss: 3.5658 - acc: 0.3057\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 209s 5ms/step - loss: 3.3867 - acc: 0.3282\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 195s 5ms/step - loss: 3.2287 - acc: 0.3497\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 201s 5ms/step - loss: 3.0901 - acc: 0.3701\n",
      "epoch:  15\n",
      "\n",
      "---Generating with seed: \"meryton was within a walk of longbourn they would be going there forever anxiety on janes behalf was another prevailing concern and mr darcys explanation by restoring bingley to all\"\n",
      "\n",
      "-------temperature:  0.2\n",
      "meryton was within a walk of longbourn they would be going there forever anxiety on janes behalf was another prevailing concern and mr darcys explanation by restoring bingley to all this room had not much better to see him at pemberley"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it is a very good room had soon at length when she had felt that i am quite many friend when the next room before their father were sought on these sort of three\n",
      "-------temperature:  0.5\n",
      "meryton was within a walk of longbourn they would be going there forever anxiety on janes behalf was another prevailing concern and mr darcys explanation by restoring bingley to all other elopement to myself they will be so objection to yourself what feeling a come to his sisters fatigued to the mortifying of his words that recommend himself by those but elizabeth had never been to do one and then there is not a step\n",
      "-------temperature:  1.0\n",
      "meryton was within a walk of longbourn they would be going there forever anxiety on janes behalf was another prevailing concern and mr darcys explanation by restoring bingley to all directly in another two wickham was what i know in leaving before one or both or every day she had not all spent in such other elizabeth can animated that to receive him than madam you my mother at pemberley that kind in anger didEpoch 1/1\n",
      "40486/40486 [==============================] - 218s 5ms/step - loss: 2.9720 - acc: 0.3879\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 293s 7ms/step - loss: 2.8270 - acc: 0.4060\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 218s 5ms/step - loss: 2.7069 - acc: 0.4215\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 286s 7ms/step - loss: 2.5865 - acc: 0.4406\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 279s 7ms/step - loss: 2.4815 - acc: 0.4566\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 244s 6ms/step - loss: 2.3867 - acc: 0.4709\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 220s 5ms/step - loss: 4.2540 - acc: 0.4139\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 209s 5ms/step - loss: 2.9192 - acc: 0.4700\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 231s 6ms/step - loss: 2.9251 - acc: 0.4872\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 192s 5ms/step - loss: 3.8249 - acc: 0.4688\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 171s 4ms/step - loss: 3.0209 - acc: 0.5007\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 173s 4ms/step - loss: 3.1411 - acc: 0.5041\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 190s 5ms/step - loss: 3.2059 - acc: 0.4893\n",
      "Epoch 1/1\n",
      "40486/40486 [==============================] - 209s 5ms/step - loss: 2.3325 - acc: 0.5353\n",
      "epoch:  29\n",
      "\n",
      "---Generating with seed: \"nature and by no means of equal magnitude you last night laid to my charge the first mentioned was that regardless of the sentiments of either i had detached mr\"\n",
      "\n",
      "-------temperature:  0.2\n",
      "nature and by no means of equal magnitude you last night laid to my charge the first mentioned was that regardless of the sentiments of either i had detached mr bingley was bitter and it had soon as he was not to be lost in the the very young family as hers she could have lost in this was so dreadfully as i am in dinner of us i am sure but to be done\n",
      "-------temperature:  0.5\n",
      "nature and by no means of equal magnitude you last night laid to my charge the first mentioned was that regardless of the sentiments of either i had detached mr at this man i am sure that he had been so well done he has the happiness of a few consequence she could knew it the subject mr darcy sat down to keep the awkwardness the business she had been tempted by her husband into\n",
      "-------temperature:  1.0\n",
      "nature and by no means of equal magnitude you last night laid to my charge the first mentioned was that regardless of the sentiments of either i had detached mr anticipating at what a leaving of ladyship up for her less if almost said lady catherine smiled the things were frightened without love that there had probably several the ball i am very well even over the the efforts of himself to leave to miss"
     ]
    }
   ],
   "source": [
    "#text generation \n",
    "for epoch in range(1,30): #training the model for 30 epochs\n",
    "    model.fit(x,y,batch_size=128,epochs=1) #fit the model\n",
    "    if(epoch == 15 or epoch == 29):\n",
    "        print('epoch: ' ,epoch)\n",
    "        #select a seed at random\n",
    "        start_index = random.randint(0,len(tokens)-maxlen-1)\n",
    "        generated_text = tokens[start_index: start_index+ maxlen]\n",
    "        generated_text = ' '.join(generated_text)\n",
    "        print('\\n---Generating with seed: \"'+ generated_text + '\"')\n",
    "        seed_text=generated_text\n",
    "        #using different temperatures\n",
    "        for temp in [0.2,0.5,1.0]:\n",
    "            print('\\n-------temperature: ',temp)\n",
    "            sys.stdout.write(seed_text)\n",
    "            for i in range(45): #generating 45 words\n",
    "                #one hot encode the words generated so far\n",
    "                sampled = np.zeros((1,maxlen,len(words)))\n",
    "                for t,word in enumerate(generated_text.split()):\n",
    "                    sampled[0,t,word_indices[word]] =1 \n",
    "                \n",
    "                #samples the next word\n",
    "                preds= model.predict(sampled, verbose=0)[0]\n",
    "                next_index = sample(preds,temp)\n",
    "                next_word = words[next_index]\n",
    "                \n",
    "                generated_text =generated_text+' '+ next_word\n",
    "                generated_text=' '.join(generated_text.split()[1:])\n",
    "                sys.stdout.write(' '+next_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Seems like the results are best at temp=0.2 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
